Sat 17 Jan 2026 02:38:05 INFO  {'seed': 2020, 'dataset': 'Musical_Instruments', 'bidirectional': False, 'n_heads': 4, 'lr': 0.001, 'tau': 0.07, 'cl_weight': 0.4, 'mlm_weight': 0.6, 'neg_num': 24000, 'text_types': ['title', 'brand', 'features', 'categories', 'description'], 'epochs': 500, 'batch_size': 100, 'num_workers': 8, 'eval_step': 1, 'learner': 'AdamW', 'data_path': './dataset', 'map_path': '.emb_map.json', 'text_index_path': '.code.pq.20_256.pca128.title_brand_features_categories_description.json', 'text_emb_path': '.t5.meta.emb.npy', 'lr_scheduler_type': 'constant', 'gradient_accumulation_steps': 1, 'warmup_steps': 500, 'weight_decay': 0.0001, 'max_his_len': 50, 'n_codes_per_lel': 256, 'code_level': 20, 'early_stop': 100, 'embedding_size': 128, 'hidden_size': 512, 'n_layers': 2, 'n_layers_cross': 2, 'dropout_prob': 0.3, 'dropout_prob_cross': 0.3, 'mask_ratio': 0.5, 'device': 'cuda:0', 'metrics': 'recall@5,ndcg@5,recall@10,ndcg@10', 'valid_metric': 'ndcg@10', 'log_dir': './logs/消融_简单相加', 'ckpt_dir': './myckpt/', 'resume': None, 'run_local_time': 'Jan-17-2026_02-38', 'save_file_name': 'Jan-17-2026_02-38-8abd51_mlm0.6_cl0.4_maskratio0.5_drop0.3_dpcross0.3'}
Sat 17 Jan 2026 02:38:35 INFO  MGFSRec(
  (query_code_embedding): Embedding(5121, 128, padding_idx=0)
  (item_text_embedding): ModuleList(
    (0-4): 5 x Embedding(24588, 128, padding_idx=0)
  )
  (qformer): CrossAttTransformer(
    (layer): ModuleList(
      (0-1): 2 x CrossAttTransformerLayer(
        (self_attention): MultiHeadAttention(
          (query): Linear(in_features=128, out_features=128, bias=True)
          (key): Linear(in_features=128, out_features=128, bias=True)
          (value): Linear(in_features=128, out_features=128, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.3, inplace=False)
          (out_linear): Linear(in_features=128, out_features=128, bias=True)
          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.3, inplace=False)
        )
        (cross_attention): MultiHeadAttention(
          (query): Linear(in_features=128, out_features=128, bias=True)
          (key): Linear(in_features=128, out_features=128, bias=True)
          (value): Linear(in_features=128, out_features=128, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.3, inplace=False)
          (out_linear): Linear(in_features=128, out_features=128, bias=True)
          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.3, inplace=False)
        )
        (feed_forward): FeedForward(
          (linear_1): Linear(in_features=128, out_features=512, bias=True)
          (linear_2): Linear(in_features=512, out_features=128, bias=True)
          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (intra_position_embedding): Embedding(50, 128)
  (intra_transformer): Transformer(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=128, out_features=128, bias=True)
          (key): Linear(in_features=128, out_features=128, bias=True)
          (value): Linear(in_features=128, out_features=128, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.3, inplace=False)
          (out_linear): Linear(in_features=128, out_features=128, bias=True)
          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.3, inplace=False)
        )
        (feed_forward): FeedForward(
          (linear_1): Linear(in_features=128, out_features=512, bias=True)
          (linear_2): Linear(in_features=512, out_features=128, bias=True)
          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (intra_layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
  (intra_dropout): Dropout(p=0.3, inplace=False)
  (inter_lstm): LSTM(128, 64, batch_first=True, bidirectional=True)
  (inter_layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
  (inter_dropout): Dropout(p=0.3, inplace=False)
  (session_position_embedding): Embedding(50, 128)
  (session_attention_w): Linear(in_features=256, out_features=128, bias=True)
  (session_attention_v): Linear(in_features=128, out_features=1, bias=False)
  (output_layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
  (loss_fct): CrossEntropyLoss()
)
Sat 17 Jan 2026 03:17:23 INFO  [Epoch 0] training [time: 2327.63s, loss: 12.7085, mlm_loss: 5.7716, rec_loss: 9.0129, cl_loss: 0.5816, ]
Sat 17 Jan 2026 03:19:03 INFO  [Epoch 0] Saving current: ./myckpt/Musical_Instruments/Jan-17-2026_02-38-8abd51_mlm0.6_cl0.4_maskratio0.5_drop0.3_dpcross0.3/best_model.pth
Sat 17 Jan 2026 03:19:03 INFO  [Epoch 0] Val Result: {'recall@5': 0.03495882588485175, 'ndcg@5': 0.022958646904249813, 'recall@10': 0.05529344173819182, 'ndcg@10': 0.029483623235167858}
Sat 17 Jan 2026 03:57:16 INFO  [Epoch 1] training [time: 2293.89s, loss: 11.5974, mlm_loss: 4.7895, rec_loss: 8.6320, cl_loss: 0.2292, ]
Sat 17 Jan 2026 03:58:58 INFO  [Epoch 1] Saving current: ./myckpt/Musical_Instruments/Jan-17-2026_02-38-8abd51_mlm0.6_cl0.4_maskratio0.5_drop0.3_dpcross0.3/best_model.pth
Sat 17 Jan 2026 03:58:58 INFO  [Epoch 1] Val Result: {'recall@5': 0.03828409268963596, 'ndcg@5': 0.024483314915456657, 'recall@10': 0.060081129546127196, 'ndcg@10': 0.03148407282467583}
